{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0711b1",
   "metadata": {},
   "source": [
    "# Exam Agenda - Q4: Projections and Least Squares\n",
    "\n",
    "## Focus on the relation between linear least squares (function minimization) and projections.\n",
    "- `05-projection-tutorial`\n",
    "    - Projection on a line, where A is a column vector\n",
    "        - Projection matrix: $P = A(A^{\\top}A)^{-1}A^{\\top}$\n",
    "        - Projected points, ($\\hat{y}$ is the projected points and y is the actual points): $\\hat{y} = Py$\n",
    "    - Linear least square: \n",
    "        - Find a line that minimises the error\n",
    "        - $y = \\mathbf{w}_1x + \\mathbf{w}_0$\n",
    "        - With mulitple points: \n",
    "        - $\\begin{array}{cccc}\n",
    "            y &= & A &w \\\\\n",
    "            \\begin{bmatrix}y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \n",
    "                &=\n",
    "                &\\begin{bmatrix}x_1 & 1 \\\\ \\vdots & \\vdots \\\\ x_n & 1\\end{bmatrix} \n",
    "                &w\n",
    "            \\end{array}$\n",
    "        - Since the projected points $\\hat{y}$ is in the span of A (see figure 2), then: $\\hat{y}=Aw$ (linear combination)\n",
    "        - Thus: $A\\mathbf{w} = P \\mathbf{y}=A(A^\\top A)^{-1}A^\\top \\mathbf{y}$\n",
    "        - By dividing A on both sides: $w = (A^{\\top}A)^{-1}A^{\\top}y$\n",
    "- Measure error once line is found\n",
    "    - RMS is used to calculate the error\n",
    "    - The further away from the line, the larger error\n",
    "    - When the linear equation is perfectly determined, RMS = 0\n",
    "    - We use least square when $n > m$\n",
    "    - Outliers on a fitted line\n",
    "\n",
    "## Focus on linear least squares problems for model fitting (design matrix, kernel, lines, polynomials, affine, and other multivariate functions) and the interpretation of results for various types of models (see week 7).\n",
    "- What is linear least squares\n",
    "    - Fits a line while minimising error\n",
    "    - More knowns than unknowns\n",
    "- Focus: Task 3 in [02-model-complexity](../w7/02-model_complexity.ipynb) week 7 (predicting growth of trees)\n",
    "    - Least square for different polynomials\n",
    "        - Design matrix for different polynomials\n",
    "            - As manny degrees of polynomials as the model (+ 1)\n",
    "            - 2 degree polynomial: $A = \\begin{bmatrix}x_1^2 & x_1 & 1\\\\\\vdots & \\vdots & \\vdots\\\\x_n^2 & x_n&1\\end{bmatrix}$\n",
    "        - Task 3 shows least squares for different polynimals\n",
    "            - 6 is overfit, does good on training but very bad on test data\n",
    "            - 1 is doing good on both training and test data\n",
    "        - Goal: find a model that performs well on training and test data\n",
    "\n",
    "## Learning of Affine (multivariate) functions and linear optimization.\n",
    "- What is an affine function\n",
    "    - Depends on multiple input parameters (both x and y)\n",
    "- Focus: [w5/02-affine_spatial_regression.ipynb](../w5/02-affine_spatial_regression.ipynb)\n",
    "    - Mapping coordinates from 3D atrium to 2D atrium\n",
    "    - This is multivariete function\n",
    "    - Affine since $w_3$ and $w_6$ is bias terms\n",
    "    - Task 1 to explain how T and A, w, b relates\n",
    "    - Task 5 reflects on how accuracy can be improved \n",
    "        - Least squares if we have more than 3 points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RR6Tyet6hydxdOYr7uQLh",
   "metadata": {},
   "source": [
    "# Experimenting with the tutorial\n",
    "The following tasks are related to the week 4 tutorial.\n",
    " \n",
    "The individual tasks will ask you to either reflect on parts of the tutorial or modify specific code cells from the tutorial. Specifically, [Task 2](#project) and [Task 3](#ls) require modifications to the code of your copy of the tutorial notebook.\n",
    " \n",
    "\n",
    "<article class=\"message\">\n",
    "    <div class=\"message-body\">\n",
    "        <strong>List of tasks</strong>\n",
    "        <ul style=\"list-style: none;\">\n",
    "            <li>\n",
    "            <a href=\"#copy\">Task 1: Copy notebook</a>\n",
    "            </li>\n",
    "            <li>\n",
    "            <a href=\"#project\">Task 2: Projection experiments</a>\n",
    "            </li>\n",
    "            <li>\n",
    "            <a href=\"#ls\">Task 3: Linear Least Squares Experiments</a>\n",
    "            </li>\n",
    "            <li>\n",
    "            <a href=\"#poly\">Task 4: Second-order polynomial</a>\n",
    "            </li>\n",
    "            <li>\n",
    "            <a href=\"#pmatrix\">Task 5: Projection matrix</a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</article>\n",
    "\n",
    "## Experiments for the tutorial notebook\n",
    "<article class=\"message task\"><a class=\"anchor\" id=\"copy\"></a>\n",
    "    <div class=\"message-header\">\n",
    "        <span>Task 1: Copy notebook</span>\n",
    "        <span class=\"has-text-right\">\n",
    "          <i class=\"bi bi-stoplights easy\"></i>\n",
    "        </span>\n",
    "    </div>\n",
    "<div class=\"message-body\">\n",
    "\n",
    "\n",
    "Copy the tutorial notebook\n",
    " in the repository. \n",
    "This makes it easy to go back to the original in case something goes wrong.\n",
    "\n",
    "\n",
    "</div></article>\n",
    "\n",
    "<article class=\"message task\"><a class=\"anchor\" id=\"project\"></a>\n",
    "    <div class=\"message-header\">\n",
    "        <span>Task 2: Projection experiments</span>\n",
    "        <span class=\"has-text-right\">\n",
    "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights easy\"></i>\n",
    "        </span>\n",
    "    </div>\n",
    "<div class=\"message-body\">\n",
    "\n",
    "\n",
    "This task builds on the $\\textbf{Projections}$ section in the tutorial.\n",
    "1. Search and identify comment `##1`\n",
    ". \n",
    "2. Change the values of the matrix $A$ (below comment `##1`\n",
    ") to modify the line. Experiment with different values and observe how the projection changes in the plot.\n",
    "3. Change the matrix $A$, such that $PX$ â‰ˆ $X$ (that is the projection leaves $X$ almost unchanged). \n",
    "4. Search and identify comment `##2`\n",
    ".\n",
    "5. Set the matrix $A$  = $\\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix}$, then apply the projection matrix $P$ twice, i.e. calculate $PPX$ (just below the comment). How does this affect the projected points?\n",
    "\n",
    "\n",
    "\n",
    "</div></article>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b593232",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hAKVuXxLEApi2t4WUSFWO",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "\n",
    "# PX nearly equals X when A = 1,1. The values are\n",
    "# projected points:\n",
    "#  [[1.  2.  2.5]\n",
    "#  [1.  2.  2.5]]\n",
    "# original points:\n",
    "#  [[1 2 3]\n",
    "#  [1 2 2]]\n",
    "\n",
    "\n",
    "# When applying P twice (x_prime = P @ P @ X) the result is\n",
    "# exactly the same as when doing it only once (x_prime = P @ X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hn535AV7ljyPWF4wqQODe",
   "metadata": {},
   "source": [
    "<article class=\"message task\"><a class=\"anchor\" id=\"ls\"></a>\n",
    "    <div class=\"message-header\">\n",
    "        <span>Task 3: Linear Least Squares Experiments</span>\n",
    "        <span class=\"has-text-right\">\n",
    "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights easy\"></i>\n",
    "        </span>\n",
    "    </div>\n",
    "<div class=\"message-body\">\n",
    "\n",
    "\n",
    "This task builds on the $\\textbf{Linear Least Squares}$ section in the tutorial.\n",
    "1. Search and identify comment `##3`\n",
    ".\n",
    "2. Change the values of the first point in the matrix `X`\n",
    " such that it gradually moves further and further away from the line. Observe how it affects the error $RMS$.\n",
    "3. Add two points to `X`\n",
    " and observe how they affect the fitted line and the error.    - How can you change the two additional points so the fitted line does not move?\n",
    "\n",
    "\n",
    "4. What happens to the error when removing all but two points from `X`\n",
    "?\n",
    "5. What happens when you remove all but one point from `X`\n",
    "?\n",
    "6. Reflect on how the quality of the data affects the projection and thus the solution. \n",
    "\n",
    "\n",
    "\n",
    "</div></article>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1Km_YwC8hhZwAEoX6Ah6R",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "# 2. As the first point moves further away from the line of two other points the rms increases.\n",
    "\n",
    "# 3. If I add two points 4,4 and 5,5 the line changes, but when I then change the two points to 6,6 and 7,7, the line does not change. If the two new points have the same distance (error) to the line as the two previos ones, then the line does not change.\n",
    "\n",
    "# 4. If you remove all but two points then the line fits perfectly and the rms is 0.\n",
    "\n",
    "# 5. If you remove all but one point, it will fail as it needs at least as many points as unknown (slope and intersection, a and b), so in this case two points.\n",
    "\n",
    "# 6. Outliers can affect the projection a lot.\n",
    "# An example is if you have one outlier (0,6), it will affect the line a lot. There is a trend of all the other points, but this one point that is off changes the line from following the trend.\n",
    "# X = np.array([\n",
    "#     [1, 1],\n",
    "#     [2, 2],\n",
    "#     [3, 2],\n",
    "#     [5,5],\n",
    "#     [6,6],\n",
    "#     [0,6]\n",
    "# ]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R3Z1DM6YcVdoVwwJdtawt",
   "metadata": {},
   "source": [
    "## Pen and paper exercises\n",
    "A 2. order polynomial is given by \n",
    "\n",
    "$$f(x) = w_0 + w_1x + w_2x^2 = \\sum^2_{i=0} w_ix^i.$$\n",
    "\n",
    "Generally, an $N$'th order  polynomial is given by\n",
    "\n",
    "$$f(x) = \\sum^N_{i=0} w_ix^i,$$\n",
    "where $\\mathbb{w}$ is a vector of coefficients.\n",
    "<article class=\"message task\"><a class=\"anchor\" id=\"poly\"></a>\n",
    "    <div class=\"message-header\">\n",
    "        <span>Task 4: Second-order polynomial</span>\n",
    "        <span class=\"has-text-right\">\n",
    "          <i class=\"bi bi-infinity\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
    "        </span>\n",
    "    </div>\n",
    "<div class=\"message-body\">\n",
    "\n",
    "\n",
    "1. Identify the knowns and unknowns in the polynomial above.\n",
    "2. Is the function linear or non-linear in $\\mathbb{w}$?\n",
    "3. Is the function linear or non-linear in $\\mathbb{x}$?\n",
    "4. Provide the outline of an algorithm for fitting a second-order polynomial using linear least squares.\n",
    "5. Generalize this algorithm to n-th order polynomials.\n",
    "\n",
    "\n",
    "\n",
    "</div></article>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DNhYRwqLRrKMrByAgL1ig",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "# 1. x and f(x) are knowns and w are unknowns\n",
    "# 2. and 3. It is linear in w and non-linear in x\n",
    "# 4. Add the x coordinates of the points to A such that the first row in A has 1's. the second has x and the third has x^2.\n",
    "# A = np.array([\n",
    "#     [1, x1, x1^2],\n",
    "#     [1, x2, x2^2],\n",
    "#     [1, x3, x3^2],\n",
    "#      ....\n",
    "# ])\n",
    "# Add all the y coordinates to a vector b\n",
    "# b = np.array([\n",
    "#     [y1],\n",
    "#     [y2],\n",
    "#     [y3],\n",
    "#      ...\n",
    "# ])\n",
    "\n",
    "# use linear least squares to find the vector w.(see the formula below)\n",
    "\n",
    "# 5. Do the exact same as described above, but change A so it has all the polynomials of x.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38197464",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{w} = (A^\\top A)^{-1}A^\\top \\mathbf{y}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OB8ks9QfVvWT30fIHCEQY",
   "metadata": {},
   "source": [
    "<article class=\"message task\"><a class=\"anchor\" id=\"pmatrix\"></a>\n",
    "    <div class=\"message-header\">\n",
    "        <span>Task 5: Projection matrix</span>\n",
    "        <span class=\"has-text-right\">\n",
    "          <i class=\"bi bi-infinity\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
    "        </span>\n",
    "    </div>\n",
    "<div class=\"message-body\">\n",
    "\n",
    "\n",
    "The projection matrix $P = A(A^\\top A )^{-1}A^\\top$ is, under certain conditions, equal to the identity matrix.\n",
    "1. Give an example of a design matrix $A$ for which $P=I$.\n",
    "2. Explain why projection matrices are usually not identity matrices.\n",
    "3. (optional) Prove a condition for which $P=I$. Hint: when is $A^\\top A=I$?.\n",
    "\n",
    "\n",
    "\n",
    "</div></article>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "itHa4tLfYTZ0cRVsY-uQs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZeK_U7PWfKWTyrxxh-z2f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
