{
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": "py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "code",
      "id": "css_setup",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "HTML(f\"\"\"\n",
        "<style>\n",
        "@import \"https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css\";\n",
        "</style>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "JAcsnPQoMQJ4-eJ407fKH",
      "metadata": {},
      "source": [
        "# Model selection and descriptive statistics\n",
        "In this exercise, you are given noisy data and methods to fit polynomial models multiple times to different subsets of the data. Your task is to use descriptive statistics (such as mean, variance, covariance, and correlation) to analyze the performance of these models and reflect on how well they fit the data. You will investigate how\n",
        "- the models capture the underlying data \n",
        "- the fit varies across different subsets of training data\n",
        "- assess how well the models perform on unseen data.\n",
        "\n",
        "## Functions and libraries\n",
        "The cell below contains functions for generating a noisy dataset and fitting a polynomial multiple times to different subsets of the generated data. More specifically:\n",
        "1. `generate_polynomial(x, coeffs)`\n",
        ":    - Generates ground truth data for a polynomial given the polynomial coefficients.\n",
        "\n",
        "\n",
        "2. `add_gaussian_noise(y, mean, variance, num_outliers)`\n",
        ":    - Adds Gaussian noise with a specified **mean** and **variance** and a number of outliers (`num_outliers`\n",
        ") to simulate noisy data.\n",
        "\n",
        "\n",
        "3. `fit_polynomial(x, y, M, N)`\n",
        ":    - Samples  $M$  random points  $(x, y)$ from the dataset and fits an $N$-th order polynomial to the points. The function returns the fitted coefficients and the mean squared error (MSE) of the fit.\n",
        "\n",
        "\n",
        "4. `iterate_fit(x, y, M, N, K)`\n",
        ":    - Performs the polynomial fitting $K$ times, each time sampling  $M$  points  $(x, y)$  and fitting a polynomial of order $N$. The method returns the mean and variance of the MSE fits of each iteration, the mean of the fitted coefficients, and their covariance and correlation matrices.\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "erZ8sLWNTLsHwR8_fzMHe",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to generate polynomial values\n",
        "def generate_polynomial(x, coeffs):\n",
        "    return np.polyval(coeffs, x)\n",
        "\n",
        "# Function to add Gaussian noise and outliers\n",
        "def add_gaussian_noise(y, mean, variance, num_outliers):\n",
        "    noisy_y = y + np.random.normal(mean, np.sqrt(variance), len(y))\n",
        "    \n",
        "    # Add outliers\n",
        "    outlier_indices = np.random.choice(range(len(noisy_y)), size=num_outliers, replace=False)\n",
        "    for idx in outlier_indices:\n",
        "        noisy_y[idx] += 10 * variance  # Adding large variance to simulate outliers\n",
        "    \n",
        "    return noisy_y\n",
        "\n",
        "# Function to sample M points and fit a polynomial of order N\n",
        "def fit_polynomial(x, y, M, N):\n",
        "    # Randomly sample M points from the dataset\n",
        "    indices = np.random.choice(len(x), M, replace=False)\n",
        "    x_sampled = x[indices]\n",
        "    y_sampled = y[indices]\n",
        "    \n",
        "    # Fit a polynomial of order N to the sampled points\n",
        "    coeffs = np.polyfit(x_sampled, y_sampled, N)\n",
        "    fitted_poly = np.poly1d(coeffs)\n",
        "    \n",
        "    # Calculate loss (mean squared error)\n",
        "    y_fitted = fitted_poly(x_sampled)\n",
        "    mse = np.mean((y_sampled - y_fitted) ** 2)\n",
        "    \n",
        "    return mse, coeffs\n",
        "\n",
        "\n",
        "# Function to iterate K times, fit the model and compute mean/variance of errors and params\n",
        "def iterate_fit(x, y, M, N, K):\n",
        "    errors = []\n",
        "    coeffs_list = []\n",
        "    \n",
        "    for _ in range(K):\n",
        "        mse, coeffs = fit_polynomial(x, y, M, N)\n",
        "        errors.append(mse)\n",
        "        coeffs_list.append(coeffs)\n",
        "    \n",
        "    # Convert lists to arrays for easier manipulation\n",
        "    errors = np.array(errors)\n",
        "    coeffs_array = np.array(coeffs_list)\n",
        "    \n",
        "    # Compute statistics\n",
        "    error_mean = np.mean(errors)\n",
        "    error_variance = np.var(errors, ddof=1)\n",
        "    coeffs_mean = np.mean(coeffs_array, axis=0)\n",
        "    coeffs_covariance = np.cov(coeffs_array, rowvar=False)\n",
        "    coeffs_correlation = np.corrcoef(coeffs_array, rowvar=False)\n",
        "    \n",
        "    return errors, coeffs_array, error_mean, error_variance, coeffs_mean, coeffs_covariance, coeffs_correlation\n",
        "\n",
        "# Function for plotting, to prepare error bars\n",
        "def prepare_error_bars(means, variances):\n",
        "    std = np.sqrt(variances)\n",
        "    lower_bound = np.maximum(0, np.array(means) - std)\n",
        "    upper_bound = np.array(means) + std\n",
        "    return [np.array(means) - lower_bound, upper_bound - np.array(means)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "RJztZJOAqaRWWLVSoOp_K",
      "metadata": {},
      "source": [
        "## Model Fitting\n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"iterate\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 1: Fitting the models</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights easy\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Run the cell below to create the inputs `x_range`\n",
        " and the noisy outputs `y_noisy`\n",
        "\n",
        "2. Use the `iterate_fit()`\n",
        " function to fit a 2nd-order polynomial to the generated inputs and outputs. Fit the model 100 times, sampling 20 points as the training data in each iteration.\n",
        "\n",
        "<article class=\"message is-warning\">\n",
        "  <div class=\"message-header\">Hint</div>\n",
        "  <div class=\"message-body\">\n",
        "\n",
        "  Observe the output of the `iterate_fit()`\n",
        " function and ensure that all variables are created accordingly.\n",
        "\n",
        "\n",
        "  </div>\n",
        "</article>\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "l93b9h79xEXYZpTmf7lvV",
      "metadata": {},
      "source": [
        "# Parameters for the dataset\n",
        "coefficients = [1, -2, 3]  # Coefficients for the polynomial (change as needed)\n",
        "x_range = np.linspace(-10, 10, 100)  # Range of x values\n",
        "mean = 0  # Mean for the Gaussian noise\n",
        "variance = 50  # Variance for the Gaussian noise\n",
        "num_outliers = 5  # Number of outliers to introduce\n",
        "\n",
        "# Generate noise-free polynomial dataset\n",
        "y_clean = generate_polynomial(x_range, coefficients)\n",
        "\n",
        "# Generate dataset with Gaussian noise and outliers\n",
        "y_noisy = add_gaussian_noise(y_clean, mean, variance, num_outliers)\n",
        "\n",
        "# Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "QUIYqYpYeAlwcGFpxUQnV",
      "metadata": {},
      "source": [
        "<article class=\"message task\"><a class=\"anchor\" id=\"reflect\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 2: Plotting the results</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-lightbulb-fill\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Run the cell below to display all fitted polynomial models and the mean fitted polynomial over the noisy data.\n",
        "\n",
        "2. What does the variability of the fitted polynomials say about the complexity of the model?\n",
        "\n",
        "3. Repeat the model fitting process with the same parameters as before, but on a noisy data with 5 and 15 outliers. Compare the results of having 0, 5 and 15 outliers. How do the outliers impact the variability of the individual models and the mean fitted polynomial?\n",
        "\n",
        "4. Repeat the model fitting process with the same parameter as before, but set the number of outliers to 0 and adjust the noise variance to 150 and then to 650. How is the mean fitted polynomial affected by the increase in the noise variance? Does noise affect the model similarly to outliers? \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "PqhCVQtW4hWfan7tgelg6",
      "metadata": {},
      "source": [
        "# Plot all fitted models and the mean fitted polynomial\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x_range, y_noisy, label='Noisy Data with Outliers', color='red', alpha=0.6)\n",
        "\n",
        "# Plot all fitted models from the iterations\n",
        "for i in range(K):\n",
        "    fitted_poly = np.poly1d(coeffs_array[i])\n",
        "    plt.plot(x_range, fitted_poly(x_range), color='gray', alpha=0.2)\n",
        "\n",
        "# Plot the mean fitted polynomial\n",
        "fitted_mean_poly = np.poly1d(coeffs_mean)\n",
        "plt.plot(x_range, fitted_mean_poly(x_range), label=f'Mean Fitted Polynomial (Order {N})', color='blue', linewidth=2)\n",
        "\n",
        "plt.title(f\"Fitted Models Over {K} Iterations and Mean Fitted Model\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "gdaPOuKSJ48Hyxyv2Ath7",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "Ok2yhOQqeO0w-UJ9j-SSU",
      "metadata": {},
      "source": [
        "# Write your reflection here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "o3dXwGQEOQu5waRT8ZgAl",
      "metadata": {},
      "source": [
        "## Generalizability\n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"modify\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 3: Test set MSE</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-lightbulb-fill\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "The following task will modify the `fit_polynomial()`\n",
        " and the `iterate_fit()`\n",
        " functions to test the model's performance on unseen data.\n",
        "1. Modify the `fit_polynomial()`\n",
        " function:    - Uncomment the line under `# Comment1`\n",
        " to create a test set and read the documentation on  [`np.setdiff1d()`\n",
        "](https://numpy.org/doc/2.0/reference/generated/numpy.setdiff1d.htmls)\n",
        "\n",
        "    - Compute `y_fitted_test`\n",
        " by applying the polynomial model to the inputs in the test set.\n",
        "    - Calculate the mean squared error (MSE) for the model’s predictions on the test data and store it in `mse_test`\n",
        ".\n",
        "\n",
        "\n",
        "2. Modify the `iterate_fit()`\n",
        " function:    - Calculate the mean (`error_mean_test`\n",
        ") and variance (`error_variance_test`\n",
        ") of the test errors and let the function return these values. \n",
        "\n",
        "\n",
        "3. Generate noisy outputs with the variance of the Gaussian noise set to $100$ and no outliers. \n",
        "4. Use the generated data to fit a 2nd-order polynomial using  `iterate_fit()`\n",
        ". Fit the model 100 times, sampling 20 points in each iteration.\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "nX77dNrrJuy4apzTFat9_",
      "metadata": {},
      "source": [
        "# 1.\n",
        "\n",
        "def fit_polynomial(x, y, M, N):\n",
        "    # Randomly sample M points from the dataset for training\n",
        "    indices = np.random.choice(len(x), M, replace=False)\n",
        "    x_sampled = x[indices]\n",
        "    y_sampled = y[indices]\n",
        "    \n",
        "    # Use the remaining points as the test set\n",
        "    # Comment1\n",
        "    # test_indices = np.setdiff1d(np.arange(len(x)), indices)\n",
        "    x_test = x[test_indices]\n",
        "    y_test = y[test_indices]\n",
        "\n",
        "    \n",
        "    # Fit a polynomial of order N to the sampled points\n",
        "    coeffs = np.polyfit(x_sampled, y_sampled, N)\n",
        "    fitted_poly = np.poly1d(coeffs)\n",
        "    \n",
        "    # Calculate training loss (mean squared error) on the sampled points\n",
        "    y_fitted_train = fitted_poly(x_sampled)\n",
        "    mse_train = np.mean((y_sampled - y_fitted_train) ** 2)\n",
        "    \n",
        "    # Calculate test loss (mean squared error) on the remaining points (unseen data)\n",
        "    y_fitted_test = None # replace\n",
        "    mse_test = None # replace\n",
        "\n",
        "    return mse_train, mse_test, coeffs\n",
        "\n",
        "\n",
        "# 2. \n",
        "def iterate_fit(x, y, M, N, K):\n",
        "    errors_train = []\n",
        "    errors_test = []\n",
        "    coeffs_list = []\n",
        "    \n",
        "    for _ in range(K):\n",
        "        # Get both training and test errors from fit_polynomial\n",
        "        mse_train, mse_test, coeffs = fit_polynomial(x, y, M, N)\n",
        "        errors_train.append(mse_train)\n",
        "        errors_test.append(mse_test)\n",
        "        coeffs_list.append(coeffs)\n",
        "    \n",
        "    # Convert lists to arrays for easier manipulation\n",
        "    errors_train = np.array(errors_train)\n",
        "    errors_test = np.array(errors_test)\n",
        "    coeffs_array = np.array(coeffs_list)\n",
        "    \n",
        "    # Compute statistics for training errors\n",
        "    error_mean_train = np.mean(errors_train)\n",
        "    error_variance_train = np.var(errors_train, ddof=1)\n",
        "    \n",
        "    # Compute statistics for test errors\n",
        "    error_mean_test = None # replace\n",
        "    error_variance_test = None # replace\n",
        "\n",
        "    # Compute coefficient statistics\n",
        "    coeffs_mean = np.mean(coeffs_array, axis=0)\n",
        "    coeffs_covariance = np.cov(coeffs_array, rowvar=False)\n",
        "    coeffs_correlation = np.corrcoef(coeffs_array, rowvar=False)\n",
        "    \n",
        "    return (errors_train, errors_test, coeffs_array, \n",
        "            error_mean_train, error_variance_train, \n",
        "            error_mean_test, error_variance_test, \n",
        "            coeffs_mean, coeffs_covariance, coeffs_correlation)\n",
        "    \n",
        "# Set parameters for sampling and fitting\n",
        "M = 20  # Number of samples to use\n",
        "N = 2   # Order of the polynomial to fit\n",
        "K = 100  # Number of iterations\n",
        "\n",
        "# 3.\n",
        "\n",
        "# Generate noisy outputs\n",
        "# Write your solution here\n",
        "y_noisy = None # replace\n",
        "\n",
        "# 4.  \n",
        "\n",
        "# Apply the updated iterate_fit(function)\n",
        "# Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "DzmfmL8SPhJSAxqKd-h4B",
      "metadata": {},
      "source": [
        "<article class=\"message task\"><a class=\"anchor\" id=\"modify\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 4: Evaluation on test set</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-lightbulb-fill\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "Run the cell below to plot the training and testing error values for each iteration (line plot on top), along with the mean errors for both the training and testing sets (box plot on bottom). Reflect on: \n",
        "1. How does the trend of the training MSE (as seen in the line plot) compare to the trend of the test MSE over the 100 iterations?\n",
        "2. What role does the variance in the test MSE play in understanding the model’s robustness on unseen data?\n",
        "3. Are there any clear outliers in the boxplot for either the mean training or test MSE? How might outliers affect your understanding of the model’s performance?\n",
        "4. From the boxplot, do the distributions of training and test MSE overlap significantly, or are they visibly different? What does this suggest about the generalization capability of the model?\n",
        "5. Based on the line plot, do any iterations show large fluctuations in the test MSE compared to the training MSE? How does this align with what you observe in the boxplot?\n",
        "6. Given the boxplot’s visualization of the MSE distributions, do the whiskers (range) for the train MSE extend further than those for the test MSE? What could explain the larger variance in train errors?\n",
        "\n",
        "<article class=\"message is-warning\">\n",
        "  <div class=\"message-header\">Hint</div>\n",
        "  <div class=\"message-body\">\n",
        "\n",
        "  Take the size of the training and testing sets into consideration.\n",
        "\n",
        "\n",
        "  </div>\n",
        "</article>\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "H5HBaUWp73_6oUFus_Dfk",
      "metadata": {},
      "source": [
        "# Plot the training and test MSE over 100 iterations\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(K), errors_train, label='Training MSE', color='blue', linewidth=2)\n",
        "plt.plot(range(K), errors_test, label='Test MSE', color='orange', linewidth=2)\n",
        "plt.title('Training and Test MSE over 100 Iterations')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot of the training and test MSE\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=[errors_train, errors_test])\n",
        "plt.xticks([0, 1], ['Training MSE', 'Test MSE'])\n",
        "plt.title('Boxplot of Training and Test Mean Squared Errors')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "XYd-2DwmrkXCagg37gI35",
      "metadata": {},
      "source": [
        "_**Write your observations here**_\n",
        "## Model complexity\n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"modify\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 5: Polynomial order</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-lightbulb-fill\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "This task experiments with fitting an increasingly more complex model to the data. The cell below performs polynomial fitting for the orders defined in the `degrees`\n",
        " array and stores the mean and variance of the training and test errors.\n",
        "1. Run the cell below to visualize the mean and variance of the training and testing MSEs across different model degrees. How does increasing model complexity impact the training and testing errors?\n",
        "2. Inspect the graph and identify at which degree does the model seem to overfit? Reflect on how this correspondsto the underlying function.\n",
        "3. Observe how the model parameters change as the polynomial order increases. Explain the reasons for the observations on the higher-order terms.\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "ooyPly-vELeUxuaiPQKmF",
      "metadata": {},
      "source": [
        "degrees = [2, 3, 4, 5, 6]  # 1st, 2nd, 3rd, and 4th order polynomials\n",
        "\n",
        "# Initialize dictionaries to store the training and test error means and variances for each degree\n",
        "error_means_train = {}\n",
        "error_variances_train = {}\n",
        "error_means_test = {}\n",
        "error_variances_test = {}\n",
        "\n",
        "# Set parameters for sampling and fitting\n",
        "M = 20  # Number of samples to use\n",
        "K = 100  # Number of iterations\n",
        "\n",
        "# Loop through each polynomial degree\n",
        "for N in degrees:\n",
        "    \n",
        "    # Perform the iterative fitting process for the current polynomial degree\n",
        "    errors_train, errors_test, _, error_mean_train, error_variance_train, error_mean_test, error_variance_test, _, _, _ = iterate_fit(x_range, y_noisy, M, N, K)\n",
        "    \n",
        "    # Store the results for training and test sets\n",
        "    error_means_train[N] = error_mean_train\n",
        "    error_variances_train[N] = error_variance_train\n",
        "    error_means_test[N] = error_mean_test\n",
        "    error_variances_test[N] = error_variance_test\n",
        "    \n",
        "\n",
        "# Data preparation\n",
        "mean_training_errors = [error_means_train[d] for d in degrees]\n",
        "mean_testing_errors = [error_means_test[d] for d in degrees]\n",
        "training_error_bars = prepare_error_bars(mean_training_errors, [error_variances_train[d] for d in degrees])\n",
        "testing_error_bars = prepare_error_bars(mean_testing_errors, [error_variances_test[d] for d in degrees])\n",
        "\n",
        "colors = ['blue', 'orange', 'green', 'red']\n",
        "\n",
        "# Create side-by-side subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "\n",
        "# Plot training errors\n",
        "axes[0].bar(degrees, mean_training_errors, color=colors, yerr=training_error_bars, capsize=5)\n",
        "axes[0].set_xticks(degrees)\n",
        "axes[0].set_title('Mean Training Errors by Polynomial Degree')\n",
        "axes[0].set_xlabel('Polynomial Degree')\n",
        "axes[0].set_ylabel('Mean Squared Error (MSE)')\n",
        "\n",
        "# Plot testing errors\n",
        "axes[1].bar(degrees, mean_testing_errors, color=colors, yerr=testing_error_bars, capsize=5)\n",
        "axes[1].set_xticks(degrees)\n",
        "axes[1].set_title('Mean Testing Errors by Polynomial Degree')\n",
        "axes[1].set_xlabel('Polynomial Degree')\n",
        "axes[1].set_ylabel('Mean Squared Error (MSE)')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "B4ut77eJAiNKIxLGjCVW9",
      "metadata": {},
      "source": [
        "<article class=\"message task\"><a class=\"anchor\" id=\"modify\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 6: Model parameters</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-lightbulb-fill\"></i><i class=\"bi bi-stoplights hard\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Run the cell below to fit a 5th-order polynomial to the data and visualize the covariance and correlation matrices of the model parameters. \n",
        "2. Which pairs of coefficients show high levels of covariance/correlation? \n",
        "3. What does the variance of the model parameters say about the performance? Could this suggest that some coefficients remain relatively stable across different samples?\n",
        "4. What does the covariance of the model parameters reveal about the performance of the model? What does this reveal about model stability? Could this indicate overfitting or sensitivity to changes in the dataset?\n",
        "5. What does the correlations between coefficients say about the redundancy of model parameters? Which model parameters contribute very little to the overall model?\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "n0OyyFXY8Qnb9kj8aLgJy",
      "metadata": {},
      "source": [
        "# Set parameters for sampling and fitting\n",
        "M = 20  # Number of samples to use\n",
        "K = 100  # Number of iterations\n",
        "N = 5\n",
        "errors_train, errors_test, coeffs_array, error_mean_train, error_variance_train, error_mean_test, error_variance_test, coeffs_mean, coeffs_covariance, coeffs_correlation = iterate_fit(x_range, y_noisy, M, N, K)\n",
        "\n",
        "# Plot the covariance matrix of the fitted polynomial coefficients\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(coeffs_covariance, annot=True, fmt='.4f', cmap='coolwarm', cbar=True)\n",
        "plt.title('Covariance Matrix of Fitted Coefficients')\n",
        "plt.xlabel('Coefficient Index')\n",
        "plt.ylabel('Coefficient Index')\n",
        "plt.show()\n",
        "\n",
        "# Plot the covariance matrix of the fitted polynomial coefficients\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(coeffs_correlation, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
        "plt.title('Correlation Matrix of Fitted Coefficients')\n",
        "plt.xlabel('Coefficient Index')\n",
        "plt.ylabel('Coefficient Index')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Gv7ut8_uB57DUHGUN6b6G",
      "metadata": {},
      "source": [
        ""
      ]
    }
  ]
}